# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WFJGQ75zXPQRRW7ZTlhlrs3Lod26SeP2
"""

import yfinance as yf
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.metrics import mean_absolute_error, mean_squared_error
from sklearn.preprocessing import StandardScaler

import tensorflow as tf
from tensorflow.keras.layers import Input, LSTM, Dense, Dropout, Embedding, Flatten, Concatenate
from tensorflow.keras.models import Model
from tensorflow.keras.callbacks import ReduceLROnPlateau
from datetime import date

# ===========================
# Helpers robustos (yfinance) - IGUAL QUE LOS TUYOS
# ===========================
def get_close_df(tickers, start, end, auto_adjust=True):
    raw = yf.download(tickers, start=start, end=end, auto_adjust=auto_adjust, group_by="column")
    if isinstance(raw.columns, pd.MultiIndex):
        if "Close" in raw.columns.get_level_values(0):
            close = raw["Close"]
        else:
            raise KeyError("No se encontró 'Close' en columnas MultiIndex.")
    else:
        if "Close" in raw.columns:
            close = raw[["Close"]].rename(columns={"Close": tickers if isinstance(tickers, str) else tickers[0]})
        else:
            raise KeyError("No se encontró 'Close' en columnas.")
    if isinstance(close, pd.Series):
        close = close.to_frame()
    return close.dropna()

def get_close_series(ticker, start, end, auto_adjust=True):
    raw = yf.download(ticker, start=start, end=end, auto_adjust=auto_adjust, group_by="column")
    close = raw["Close"] if not isinstance(raw.columns, pd.MultiIndex) else raw["Close"]
    if isinstance(close, pd.DataFrame):
        close = close.iloc[:, 0]
    close = close.dropna()
    close.name = "Close"
    return close

# ===========================
# 1) Config
# ===========================
tickers = ["AAPL","MSFT","TSLA","AMZN","GOOGL"]
start = "2020-03-01"
end = pd.Timestamp.today().strftime("%Y-%m-%d")

window_size = 30     # para retornos suele funcionar 20-60
epochs = 30
batch_size = 128
train_frac = 0.8

# ===========================
# 2) Construir el MISMO panel econométrico (r, rm, d_tasa)
# ===========================
px = get_close_df(tickers, start, end, auto_adjust=True)
px = px[[t for t in tickers if t in px.columns]].dropna()

rets = np.log(px).diff().dropna()  # r_it

mkt_close = get_close_series("SPY", start, end, auto_adjust=True)
rm = np.log(mkt_close).diff().dropna()
rm.name = "rm"

tnx_close = get_close_series("^TNX", start, end, auto_adjust=True)
d_tasa = tnx_close.diff().dropna()
d_tasa.name = "d_tasa"

rm_df = rm.reset_index()
rm_df.columns = ["Date","rm"]
dt_df = d_tasa.reset_index()
dt_df.columns = ["Date","d_tasa"]

df = rets.stack().reset_index()
df.columns = ["Date","Ticker","r"]
df = df.merge(rm_df, on="Date", how="inner")
df = df.merge(dt_df, on="Date", how="inner")

df = df.sort_values(["Ticker","Date"]).reset_index(drop=True)

# ===========================
# 3) Crear secuencias LSTM por ticker
# Features por timestep: [r_{t-1}, rm_t, d_tasa_t] (podrías añadir más)
# Target: r_t
# ===========================
ticker_to_id = {t:i for i,t in enumerate(tickers)}
id_to_ticker = {i:t for t,i in ticker_to_id.items()}

X_seq, X_id, y, dates = [], [], [], []

# Escalado (global) para features. Para retornos suele ser mejor StandardScaler.
scaler = StandardScaler()

# Primero armamos un DF "global" de features para fit del scaler
df_feat = df[["r","rm","d_tasa"]].copy()
df_feat = df_feat.replace([np.inf, -np.inf], np.nan).dropna()
scaler.fit(df_feat.values)

for t in tickers:
    dft = df[df["Ticker"] == t].copy().sort_values("Date")
    if len(dft) <= window_size + 5:
        continue

    feats = dft[["r","rm","d_tasa"]].values
    feats = scaler.transform(feats)

    r_scaled = feats[:, 0]  # primera col = r escalada

    for i in range(window_size, len(dft)):
        # secuencia de window_size pasos con 3 features
        X_seq.append(feats[i-window_size:i, :])
        X_id.append(ticker_to_id[t])
        y.append(r_scaled[i])             # target = r escalada en t
        dates.append(dft["Date"].iloc[i])

X_seq = np.array(X_seq, dtype=np.float32)        # (N, window, 3)
X_id  = np.array(X_id, dtype=np.int32)          # (N,)
y     = np.array(y, dtype=np.float32)           # (N,)
dates = np.array(dates)

print("X_seq:", X_seq.shape, "X_id:", X_id.shape, "y:", y.shape)

# ===========================
# 4) Split temporal global (por fecha)
# ===========================
order = np.argsort(dates)
X_seq, X_id, y, dates = X_seq[order], X_id[order], y[order], dates[order]

cut = int(len(y) * train_frac)
X_seq_tr, X_seq_te = X_seq[:cut], X_seq[cut:]
X_id_tr,  X_id_te  = X_id[:cut],  X_id[cut:]
y_tr,     y_te     = y[:cut],     y[cut:]
dates_te          = dates[cut:]

# ===========================
# 5) Modelo LSTM panel con Embedding ticker
# ===========================
n_tickers = len(tickers)
embed_dim = min(8, n_tickers)

seq_in = Input(shape=(window_size, 3), name="seq_in")
id_in  = Input(shape=(), dtype="int32", name="ticker_id")

x = LSTM(64, return_sequences=True)(seq_in)
x = Dropout(0.2)(x)
x = LSTM(32)(x)
x = Dropout(0.2)(x)

e = Embedding(input_dim=n_tickers, output_dim=embed_dim)(id_in)
e = Flatten()(e)

h = Concatenate()([x, e])
h = Dense(32, activation="relu")(h)
out = Dense(1)(h)

model = Model([seq_in, id_in], out)
model.compile(optimizer=tf.keras.optimizers.Adam(1e-3), loss="mse")
model.summary()

reduce_lr = ReduceLROnPlateau(monitor="val_loss", factor=0.5, patience=3, verbose=1)

hist = model.fit(
    {"seq_in": X_seq_tr, "ticker_id": X_id_tr},
    y_tr,
    validation_split=0.1,
    epochs=epochs,
    batch_size=batch_size,
    callbacks=[reduce_lr],
    verbose=1
)

# ===========================
# 6) Evaluación: métricas en escala original (retornos)
# ===========================
yhat = model.predict({"seq_in": X_seq_te, "ticker_id": X_id_te}, verbose=0).flatten()

# Invertir escala SOLO para r (primera col). Truco: reconstruir vector [r,rm,d_tasa] con ceros para inversa.
def inv_r(r_scaled):
    dummy = np.zeros((len(r_scaled), 3), dtype=np.float64)
    dummy[:, 0] = r_scaled
    inv = scaler.inverse_transform(dummy)
    return inv[:, 0]

y_te_real = inv_r(y_te)
yhat_real = inv_r(yhat)

mae = mean_absolute_error(y_te_real, yhat_real)
rmse = np.sqrt(mean_squared_error(y_te_real, yhat_real))

print("\n=== LSTM PANEL (retornos) ===")
print(f"MAE:  {mae:.6f}")
print(f"RMSE: {rmse:.6f}")

# Métricas por ticker
for t in tickers:
    mask = (X_id_te == ticker_to_id[t])
    if mask.sum() < 50:
        continue
    mae_t = mean_absolute_error(y_te_real[mask], yhat_real[mask])
    rmse_t = np.sqrt(mean_squared_error(y_te_real[mask], yhat_real[mask]))
    print(f"{t}: MAE={mae_t:.6f} | RMSE={rmse_t:.6f}")

# Plot ejemplo por ticker
def plot_ticker(ticker):
    mask = (X_id_te == ticker_to_id[ticker])
    d = dates_te[mask]
    plt.figure(figsize=(12,4))
    plt.plot(d, y_te_real[mask], label="Real")
    plt.plot(d, yhat_real[mask], label="Pred")
    plt.title(f"{ticker} – Retornos: Real vs Pred (LSTM Panel)")
    plt.legend()
    plt.show()

plot_ticker("AAPL")
